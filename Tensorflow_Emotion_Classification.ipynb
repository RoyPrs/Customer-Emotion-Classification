{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8aa87-572f-4063-a2e3-95ee21a8076f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6201129-29b1-4df6-b5b7-bc66fc6ff7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import random\n",
    "# import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import linregress\n",
    "\n",
    "import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27ea44ec-4d28-427b-a176-a9d8b1903c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "MAXLEN = 4\n",
    "TRUNCATING = 'post'\n",
    "PADDING = 'post'\n",
    "OOV_TOKEN = \"<OOV>\"\n",
    "MAX_EXAMPLES = 16000\n",
    "TRAINING_SPLIT = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86072e2c-e771-4e37-8023-07cc24294fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = datasets.load_dataset('emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028c89bf-a60b-49f7-9a5d-1b856c223786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions.set_format(type=\"pandas\")\n",
    "train = emotions[\"train\"][:]\n",
    "test = emotions[\"test\"][:]\n",
    "val = emotions[\"validation\"][:]\n",
    "\n",
    "train.shape\n",
    "# test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cfa31be-90ba-4886-a325-e0c533a45dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.concat([train[\"text\"], val[\"text\"]])\n",
    "y_train = pd.concat([train[\"label\"], val[\"label\"]])\n",
    "test_text = test[\"text\"]\n",
    "y_test = test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee1d056-40ce-4d7e-ac66-5a7133834784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b2ea082-b77c-4669-ab59-a1077aa5f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tokenizer(train_sentences, oov_token):\n",
    "    \"\"\"\n",
    "    Instantiates the Tokenizer class on the training sentences\n",
    "    Args:\n",
    "        train_sentences (list of string): lower-cased sentences without stopwords to be used for training\n",
    "        oov_token (string) - symbol for the out-of-vocabulary token\n",
    "    Returns:\n",
    "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer = Tokenizer(oov_token=oov_token)\n",
    "    tokenizer.fit_on_texts(train_sentences)\n",
    "        \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6edbe41-93bd-4d8f-a657-3769d7a0eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary contains 16197 words\n",
      "\n",
      "<OOV> token included in vocabulary\n",
      "\n",
      "index of word 'i' should be 2\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "tokenizer = fit_tokenizer(train_text, OOV_TOKEN)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "VOCAB_SIZE = len(word_index)\n",
    "\n",
    "print(f\"Vocabulary contains {VOCAB_SIZE} words\\n\")\n",
    "print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")\n",
    "print(f\"\\nindex of word 'i' should be {word_index['i']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bfb48dc-d86a-4e88-bce3-7d6569d2e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_pad_and_trunc(sentences, tokenizer, padding, truncating, maxlen):\n",
    "    \"\"\"\n",
    "    Generates an array of token sequences and pads them to the same length\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of string): list of sentences to tokenize and pad\n",
    "        tokenizer (object): Tokenizer instance containing the word-index dictionary\n",
    "        padding (string): type of padding to use\n",
    "        truncating (string): type of truncating to use\n",
    "        maxlen (int): maximum length of the token sequence\n",
    "    \n",
    "    Returns:\n",
    "        pad_trunc_sequences (array of int): tokenized sentences padded to the same length\n",
    "    \"\"\"        \n",
    "       \n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    pad_trunc_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding, truncating=truncating)\n",
    "        \n",
    "    return pad_trunc_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2219b4ef-ad88-436a-9129-16ff265e665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded and truncated training sequences have shape: (18000, 16)\n",
      "\n",
      "Padded and truncated validation sequences have shape: (2000, 16)\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "train_pad_trunc_seq = seq_pad_and_trunc(train_text, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
    "test_pad_trunc_seq = seq_pad_and_trunc(test_text, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
    "\n",
    "print(f\"Padded and truncated training sequences have shape: {train_pad_trunc_seq.shape}\\n\")\n",
    "print(f\"Padded and truncated validation sequences have shape: {test_pad_trunc_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18108d62-a3ff-4096-aaf9-7a9add2f8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1526ce08-2fe7-4ba2-92db-b33b9dfaee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523f756-6242-4473-8a0c-4b9fad243641",
   "metadata": {},
   "source": [
    "## Using pre-defined Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "febd9364-0341-4809-84f7-21ffbbd8adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILE = 'Assets/glove.6B.200d.txt'\n",
    "enc = 'utf-16'\n",
    "enc = 'iso-8859-15'\n",
    "\n",
    "GLOVE_EMBEDDINGS = {}\n",
    "\n",
    "with open(GLOVE_FILE, encoding=enc) as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" \")\n",
    "        word = values[0]\n",
    "        # print(word)\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        GLOVE_EMBEDDINGS[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f246780b-a468-4d65-8cad-b0a363ee5c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GLOVE_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4465b6c6-b237-4932-8fb2-7c7d2080d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between two NumPy arrays (vectors).\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = norm(vec1)\n",
    "    norm_vec2 = norm(vec2)\n",
    "\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0  # Handle cases where one or both vectors are zero vectors\n",
    "\n",
    "    cosine_similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "982c1bf3-0acc-419d-97f6-7694e6d9fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of words woman and queen:\n",
      "\n",
      "0.4188632071018219\n"
     ]
    }
   ],
   "source": [
    "test_word1 = 'woman'\n",
    "test_word2 = 'queen'\n",
    "\n",
    "test_vector1 = GLOVE_EMBEDDINGS[test_word1]\n",
    "test_vector2 = GLOVE_EMBEDDINGS[test_word2]\n",
    "\n",
    "similarity = calculate_cosine_similarity(test_vector1, test_vector2)\n",
    "\n",
    "print(f\"Cosine similarity of words {test_word1} and {test_word2}:\\n\\n{similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d29869e6-28a1-4968-adb7-764dd4c2b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_MATRIX = np.zeros((VOCAB_SIZE+1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = GLOVE_EMBEDDINGS.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        EMBEDDINGS_MATRIX[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90223dd6-0035-40ec-a55f-884e76d1aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "lstm1_dim = 64\n",
    "lstm2_dim = 4\n",
    "dense_dim = 32\n",
    "\n",
    "def create_model(vocab_size, lstm1_dim, lstm2_dim, embedding_dim, maxlen, embeddings_matrix):\n",
    "    \"\"\"\n",
    "    Creates a binary sentiment classifier model\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): size of the vocabulary for the Embedding layer input\n",
    "        embedding_dim (int): dimensionality of the Embedding layer output\n",
    "        maxlen (int): length of the input sequences\n",
    "        embeddings_matrix (array): predefined weights of the embeddings\n",
    "    \n",
    "    Returns:\n",
    "        model (tf.keras Model): the sentiment classifier model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential([ \n",
    "        # This is how you need to set the Embedding layer when using pre-trained embeddings\n",
    "        tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, weights=[embeddings_matrix], trainable=False), \n",
    "        # tf.keras.layers.Dropout(0.2),\n",
    "        # tf.keras.layers.Conv1D(32, 5, activation='relu'),\n",
    "        # tf.keras.layers.GlobalMaxPooling1D(),\n",
    "        # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
    "        # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm1_dim, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm2_dim)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(6, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='SparseCategoricalCrossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy']) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "722043d0-508f-4e30-be5e-a78e6bc08016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.3760 - loss: 1.5671 - val_accuracy: 0.5370 - val_loss: 1.2343\n",
      "Epoch 2/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5396 - loss: 1.2406 - val_accuracy: 0.6565 - val_loss: 0.9811\n",
      "Epoch 3/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6443 - loss: 0.9952 - val_accuracy: 0.7125 - val_loss: 0.8332\n",
      "Epoch 4/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6994 - loss: 0.8592 - val_accuracy: 0.7470 - val_loss: 0.7515\n",
      "Epoch 5/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7414 - loss: 0.7529 - val_accuracy: 0.7670 - val_loss: 0.6973\n",
      "Epoch 6/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7523 - loss: 0.7141 - val_accuracy: 0.7725 - val_loss: 0.6641\n",
      "Epoch 7/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7679 - loss: 0.6766 - val_accuracy: 0.7720 - val_loss: 0.6465\n",
      "Epoch 8/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7682 - loss: 0.6585 - val_accuracy: 0.7750 - val_loss: 0.6411\n",
      "Epoch 9/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7740 - loss: 0.6382 - val_accuracy: 0.7845 - val_loss: 0.6164\n",
      "Epoch 10/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7842 - loss: 0.6134 - val_accuracy: 0.7775 - val_loss: 0.6223\n",
      "Epoch 11/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7869 - loss: 0.6077 - val_accuracy: 0.7820 - val_loss: 0.6061\n",
      "Epoch 12/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7903 - loss: 0.5877 - val_accuracy: 0.7830 - val_loss: 0.6026\n",
      "Epoch 13/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7951 - loss: 0.5785 - val_accuracy: 0.7855 - val_loss: 0.5891\n",
      "Epoch 14/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7965 - loss: 0.5600 - val_accuracy: 0.7800 - val_loss: 0.5937\n",
      "Epoch 15/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7975 - loss: 0.5604 - val_accuracy: 0.7860 - val_loss: 0.5963\n",
      "Epoch 16/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8073 - loss: 0.5479 - val_accuracy: 0.7830 - val_loss: 0.5889\n",
      "Epoch 17/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8007 - loss: 0.5552 - val_accuracy: 0.7785 - val_loss: 0.6014\n",
      "Epoch 18/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8047 - loss: 0.5310 - val_accuracy: 0.7840 - val_loss: 0.5821\n",
      "Epoch 19/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.5162 - val_accuracy: 0.7890 - val_loss: 0.5763\n",
      "Epoch 20/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8056 - loss: 0.5340 - val_accuracy: 0.7900 - val_loss: 0.5751\n",
      "Epoch 21/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8083 - loss: 0.5237 - val_accuracy: 0.7850 - val_loss: 0.5709\n",
      "Epoch 22/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8113 - loss: 0.5124 - val_accuracy: 0.7870 - val_loss: 0.5730\n",
      "Epoch 23/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8112 - loss: 0.5155 - val_accuracy: 0.7855 - val_loss: 0.5696\n",
      "Epoch 24/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8175 - loss: 0.5122 - val_accuracy: 0.7860 - val_loss: 0.5805\n",
      "Epoch 25/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8146 - loss: 0.5028 - val_accuracy: 0.7850 - val_loss: 0.5693\n",
      "Epoch 26/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8215 - loss: 0.4812 - val_accuracy: 0.7935 - val_loss: 0.5625\n",
      "Epoch 27/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8192 - loss: 0.4930 - val_accuracy: 0.7890 - val_loss: 0.5674\n",
      "Epoch 28/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8188 - loss: 0.4927 - val_accuracy: 0.7765 - val_loss: 0.6082\n",
      "Epoch 29/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8226 - loss: 0.4832 - val_accuracy: 0.7850 - val_loss: 0.5605\n",
      "Epoch 30/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8193 - loss: 0.4915 - val_accuracy: 0.7865 - val_loss: 0.5518\n"
     ]
    }
   ],
   "source": [
    "model = create_model(VOCAB_SIZE, lstm1_dim, lstm2_dim, EMBEDDING_DIM, MAXLEN, EMBEDDINGS_MATRIX)\n",
    "\n",
    "history = model.fit(train_pad_trunc_seq, y_train, epochs=30, validation_data=(test_pad_trunc_seq, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa80c40a-6d87-4db4-ac43-d652e7c11b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.337000\n",
       "0    0.289778\n",
       "3    0.135222\n",
       "4    0.119389\n",
       "2    0.082333\n",
       "5    0.036278\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979e2b0-0393-44f0-a45e-7e0f9967fd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
